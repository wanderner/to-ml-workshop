{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EqFHRKCR6CZ"
      },
      "source": [
        "# Yapay Zeka Atölyesi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-_qzlZtR6Cb"
      },
      "source": [
        "_This notebook is partially adapted from Aurélien Geron's [handson-ml3](https://github.com/ageron/handson-ml3) repository. [See license](https://github.com/ageron/handson-ml3/blob/main/LICENSE) for terms and conditions._\n",
        "\n",
        "_Adapted by Abdurrahman Can (acan [at] respectgs.us) for Tefakkuh Okulu's ML Workshop._\n",
        "\n",
        "*1 March 2024*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Bze-sTTR6Cb"
      },
      "source": [
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a href=\"https://colab.research.google.com/github/wanderner/to-ml-workshop/blob/main/Yapay_Zeka_Atolyesi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tefakkuh Okulu'nun Yapay Zeka Atölyesine hoş geldiniz! Böyle bir çalışmayı ilk defa yapıyoruz. Bu sebeple kendimizi geliştirebilme adına atölye süresince ve sonunda geri dönüşlerinizle bizleri desteklemenizi rica ediyoruz.\n",
        "\n",
        "**İnteraktif not defterleri:** Şu an da okumuş olduğunuz bir interaktif not defteri. Bu not defteri üzerinde yazı ve kod bir arada bulunuyor. Eğitim amaçlı kullanımlar için birebir olmakla beraber, akademik araştırmalarda ve yapay zeka sektöründe interaktif not defterleri yaygın olarak kullanılıyor. Bundan sonrasında *Jupyter Notebook* olarak anılacaktır.\n",
        "\n",
        "**Cloud üzerinde geliştirme:** Pratiklik olması adına sizlerden bilgisayarınıza herhangi bir kurulum yapmanızı istemedik. Aşağıdaki kodları çalıştırdığımızda bu kodlar kendi bilgisayarımız üzerinde çalışmıyor. Şu an Google Colab ürününü kullanıyoruz ve siz kod çalıştırdığınızda bunlar veri merkezlerindeki (data centers) bilgisayarlarda çalıştırılıyor ve sonuçları internet üzerinden size gösteriliyor. Bu pratiğe *cloud development* (bulutta geliştirme) veya *remote development* (uzaktan geliştirme) deniyor. Tahmin edileceği üzere bu pratik de sektörde oldukça yaygın."
      ],
      "metadata": {
        "id": "yAb_ZY1TrZu5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H81UJjrBR6Cc"
      },
      "source": [
        "## Kurulum"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9vOgcFeR6Cc"
      },
      "source": [
        "**Yazılım kütüphaneleri:** Yazılım dünyasında sıfırdan başlayarak geliştirme yapılmaz. Yapay zeka için de 'kod' yazdığımızdan ötürü daha önce yazılan ve yayınlanan kütüphaneleri (library) kullanıyoruz. Bu sayede hızlı geliştirme yapabilmemiz mümkün oluyor.\n",
        "\n",
        "**Açık kaynak:** Yazılım kütüphaneleri açık kaynak yöntemiyle kolektif bir şekilde geliştiriliyor. Bu sayede performans bakımından optimize edilmiş, güvenli ve stabil sistemler geliştirmek mümkün oluyor.\n",
        "\n",
        "Aşağıda makine öğrenmesi ve yapay zekada yaygın kullanılan bazı kütüphaneleri listeledik. Her detayın anlaşılması gerekli olmasa da bu alandan bir tat almak isterseniz websitelerini gezebilir, dokümantasyonlarına göz atabilirsiniz:\n",
        "\n",
        "*   Numpy\n",
        "*   Pandas\n",
        "*   Tensorflow\n",
        "*   PyTorch\n",
        "*   scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Şimdi başlayabiliriz. Öncelikle kullanabilme amacıyla kütüphanelerimizi ekliyoruz."
      ],
      "metadata": {
        "id": "mbILw4hUuRMW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_ekDMzQR6Cc"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "# Python >= 3.7 versiyonuna ihtiyacımız var.\n",
        "assert sys.version_info >= (3, 7)\n",
        "\n",
        "sys.version_info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fKSPiq_R6Cc"
      },
      "source": [
        "Diğer kullandığımız kütüphaneler:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTH6rkLgR6Cc"
      },
      "outputs": [],
      "source": [
        "from packaging import version\n",
        "\n",
        "# scikit-learn, klasik makine öğrenmesinde (classical machine learning)\n",
        "# kullandığımız bir kütüphanedir.\n",
        "import sklearn\n",
        "\n",
        "assert version.parse(sklearn.__version__) >= version.parse(\"1.0.1\")\n",
        "\n",
        "# matplotlib, çeşitli grafikler çizmemizi ve görselleştirmeler yapmamızı sağlar.\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Görsellerimizin daha düzenli görünmesi için bazı ayarlar yapıyoruz.\n",
        "plt.rc('font', size=14)\n",
        "plt.rc('axes', labelsize=14, titlesize=14)\n",
        "plt.rc('legend', fontsize=14)\n",
        "plt.rc('xtick', labelsize=10)\n",
        "plt.rc('ytick', labelsize=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hAjgSxJR6Cd"
      },
      "source": [
        "Aşağıda kodlarda çıktılarımızın daha temiz görünmesi adına birtakım hack'ler yer alıyor. Dolayısıyla bu kısmın anlaşılması gerekmiyor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCs6UOEAR6Cd"
      },
      "outputs": [],
      "source": [
        "# Generate and save image\n",
        "from pathlib import Path\n",
        "\n",
        "IMAGES_PATH = Path() / \"images\" / \"classification\"\n",
        "IMAGES_PATH.mkdir(parents=True, exist_ok=True)\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = IMAGES_PATH / f\"{fig_id}.{fig_extension}\"\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
        "\n",
        "# Wrap long lines:\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('<style>pre {white-space: pre-wrap;}</style>'))\n",
        "get_ipython().events.register('pre_run_cell', set_css)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BELkIs7vR6Cd"
      },
      "source": [
        "# Yapay Zeka ile Sınıflandırma (Classification)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yapay zekada çeşitli görev türleri bulunur:\n",
        "\n",
        "*   Classification (Sınıflandırma)\n",
        "*   Clustering (Kümelendirme)\n",
        "*   Anomaly detection (Anormallik bulma)\n",
        "*   Natural Language Processing (Doğal dil işleme)\n",
        "\n",
        "Bunlardan en basiti sınıflandırma olduğu için şimdi bir sınıflandırma eğitimi gerçekleştireceğiz.\n",
        "\n",
        "Makine öğrenmesi için aşağıdakilere ihtiyacımız var:\n",
        "\n",
        "1. Dataset (Veriseti)\n",
        "2. Model\n",
        "3. Computing power (İşleme gücü)"
      ],
      "metadata": {
        "id": "eb_tlWizwIgT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Veriseti: MNIST Dataset (MNIST Veriseti)\n",
        "\n",
        "Bugün yapay zekaya başlangıçta eğitim amaçlı yaygın olarak kullanılan MNIST verisetini kullanacağız. Verisetimiz el yazılarıyla oluşturulmuş rakamlardan oluşuyor."
      ],
      "metadata": {
        "id": "SVu40LpawOYm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_mGh3XTR6Cd"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "\n",
        "mnist = fetch_openml('mnist_784', as_frame=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MNIST verisetinin yazarları tarafından yazılan açıklama metnini görelim:"
      ],
      "metadata": {
        "id": "hm2JusLP9_1J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OM_sCZ4TR6Cd"
      },
      "outputs": [],
      "source": [
        "print(mnist.DESCR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3mvk9U3FR6Ce"
      },
      "outputs": [],
      "source": [
        "mnist.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MNIST verisetinde çeşitli detaylar yer alıyor. Biz sadece data ve target'i kullanacağız.\n",
        "\n",
        "Data el yazılarının verisi, target ise o el yazısının ifade ettiği sayı.\n",
        "\n",
        "Data'yı X, target'i y olarak isimlendiriyoruz."
      ],
      "metadata": {
        "id": "Elqk7xpf96jt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74iWvIIIR6Ce"
      },
      "outputs": [],
      "source": [
        "X, y = mnist.data, mnist.target"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "X'i görelim:\n"
      ],
      "metadata": {
        "id": "cyIgFxvJ_UY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "id": "_tSG2HyW_RgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "X'in şekline bakalım:"
      ],
      "metadata": {
        "id": "Q5_G0EM5_YFD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ykrhMkNXR6Ce"
      },
      "outputs": [],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "70 bin adet el yazısı sayı var, her el yazısı 784 farklı numarayla ifade edilmiş. Bu da 28 * 28 bir kare şekil ifade ediyor."
      ],
      "metadata": {
        "id": "vhzL9exA_b7S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "28 * 28"
      ],
      "metadata": {
        "id": "o9w0cKQf_290"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HL8CLviRR6Ce"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_digit(image_data):\n",
        "    image = image_data.reshape(28, 28)\n",
        "    plt.imshow(image, cmap=\"binary\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "some_digit = X[0]\n",
        "plot_digit(some_digit)\n",
        "save_fig(\"some_digit_plot\")  # extra code\n",
        "plt.show()\n",
        "\n",
        "print(y[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Şimdi de y'yi görelim:"
      ],
      "metadata": {
        "id": "aBA9W-Bd_q7Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jt-RKSZIR6Ce"
      },
      "outputs": [],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "y'nin şekli:"
      ],
      "metadata": {
        "id": "6uoVRyZ9_ltm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qdJ-mB3qR6Ce"
      },
      "outputs": [],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ve y:"
      ],
      "metadata": {
        "id": "RJtLLJ1Iw6He"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cL4xZ_3CR6Cf"
      },
      "outputs": [],
      "source": [
        "y[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verisetini daha iyi gözlemleyebilmek adına çeşitli sayıları görelim:"
      ],
      "metadata": {
        "id": "0rHNcTY0ALfy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBcEAzPwR6Cf"
      },
      "outputs": [],
      "source": [
        "# extra code – this cell generates and saves Figure 3–2\n",
        "plt.figure(figsize=(9, 9))\n",
        "for idx, image_data in enumerate(X[:100]):\n",
        "    plt.subplot(10, 10, idx + 1)\n",
        "    plot_digit(image_data)\n",
        "plt.subplots_adjust(wspace=0, hspace=0)\n",
        "save_fig(\"more_digits_plot\", tight_layout=False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Verisetinin Bölümlenmesi\n",
        "\n",
        "Elimizde 70 bin veri bulunuyor. Bunu iki gruba bölmemiz gerekiyor:\n",
        "\n",
        "1. **Training set (Eğitim seti):** Modelimizi eğitmek için bu seti kullanıyoruz. Eğitim süresinde 784 numaralık veriyi ve karşılığı olan sayıyı modelimize veriyoruz.\n",
        "2. **Test set:** Belirli bir eğitimden süresinden sonra modelimizi test etmek için bu seti kullanıyoruz. Eğitilen modelimize elimizdeki sayıların ne olduğunu söylemeden tahmin etmesini istiyoruz. Modelin verdiği sonuçları asıl sonuçlarla karşılaştırıp ne kadar isabetli çalıştığını bu sayede belirleyebileceğiz.\n",
        "\n",
        "Modelin tamamını eğiteceğimizi düşünürsek test için 10 bin veri ayırmamız yeterli. Eğitim içinse daha fazla veriye ihtiyacımız var. Dolayısıyla 60 bin ve 10 bin olarak ayırabiliriz. Ancak çalıştırma süresinin uzamaması adına bugün verisetinin sadece bir kısmını kullanacağız."
      ],
      "metadata": {
        "id": "1jaG3mQzBgSC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nv18CIq2R6Cf"
      },
      "outputs": [],
      "source": [
        "# Tüm verisetini kullanmak için aşağıdaki iki satırı kullanın:\n",
        "# X_train, X_test = X[:60000], X[60000:]\n",
        "# y_train, y_test = y[:60000], y[60000:]\n",
        "\n",
        "X_train, X_test = X[:2000], X[2000:3000]\n",
        "y_train, y_test = y[:2000], y[2000:3000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TlgRLuNR6Ck"
      },
      "source": [
        "## Çok Sınıflı Sınıflandırma (Multiclass Classification)\n",
        "\n",
        "Elimizde ikiden fazla sınıf varsa buna Multiclass Classification ismi veriyoruz. Rakam sınıflandırma yaparken 10 farklı rakamımız olduğu için elimizde 10 sınıf var.\n",
        "\n",
        "Multiclass Classification için pek çok yöntem kullanabiliriz. Bunların en genelgeçer ve kabul görenlerinden birisi Support Vector Machines, SVM'dir. Kıcasa SVM'ler, verileri daha kolay sınıflandırabilmek için üst seviye boyutlara çevirip sınıflandırma işlemini uygular ve tekrar önceki boyuta döner. Daha teknik bilgi bugün konumuz dışı olduğundan meraklısına internet üzerinde araştırmasını tavsiye ediyoruz.\n",
        "\n",
        "SVM'lerin çalışması veriseti büyüdükçe daha da uzar. Atölye sırasında uzun süre beklememek adına MNIST verisetimizin sadece ilk 2000 verisini eğitim için kullanacağız."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EGOmzD-PR6Cl"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# Modelimizi her çalıştırdığımızda herkeste aynı sonucu vermesi için rastgele\n",
        "# sayı üretme yöntemini sabitliyoruz.\n",
        "svm_clf = SVC(random_state=42)\n",
        "\n",
        "# fit() metodu bizim için fazlasıyla soyutlanmış olduğu için kodumuz\n",
        "# oldukça temiz. Burası eğitim olarak adlandırdığımız aksiyonun gerçekleştiği\n",
        "# yer:\n",
        "svm_clf.fit(X_train[:2000], y_train[:2000])  # y_train, not y_train_5"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Python'da her metodun dokümanını okumanın oldukça basit bir yolu var:"
      ],
      "metadata": {
        "id": "8yz5wtixFLp0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "help(svm_clf.fit)"
      ],
      "metadata": {
        "id": "Z1gKNU33FRbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelimizin sınıflarını görelim:"
      ],
      "metadata": {
        "id": "7sWB7CANvulb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svm_clf.classes_"
      ],
      "metadata": {
        "id": "rBgMEo_lvsfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verisetimizden sadece bir örneği tahmin ettirelim:"
      ],
      "metadata": {
        "id": "Q74o8-0nF_rZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uDPqZg8LR6Cl"
      },
      "outputs": [],
      "source": [
        "some_digit = X[0]\n",
        "\n",
        "svm_clf.predict([some_digit])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10 tane sınıfımız olduğu için modelimiz aslında 10 tane skor veriyor:"
      ],
      "metadata": {
        "id": "ZYNZ4xz4GAyM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLDKfHq6R6Cl"
      },
      "outputs": [],
      "source": [
        "some_digit_scores = svm_clf.decision_function([some_digit])\n",
        "some_digit_scores.round(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ve biz bu skorlardan en yüksek olanı alıyoruz:"
      ],
      "metadata": {
        "id": "MDU7PkqoGDwH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pj4Wx_8NR6Cl"
      },
      "outputs": [],
      "source": [
        "class_id = some_digit_scores.argmax()\n",
        "class_id"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sınıflarımızdan o indeksteki değeri görelim. Bu bizim tahmin sonucumuz:"
      ],
      "metadata": {
        "id": "k5HnEZvzv2Ai"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CA_HgBm7R6Cl"
      },
      "outputs": [],
      "source": [
        "svm_clf.classes_[class_id]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Son olarak tüm test verisetimizi verip modelin skorunu görelim:"
      ],
      "metadata": {
        "id": "XQT2P4P7v7hA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svm_clf.score(X_test, y_test)"
      ],
      "metadata": {
        "id": "vfaihMqkHAK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning (Öğrenim Transferi)"
      ],
      "metadata": {
        "id": "I_RGLc_UWX49"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Natural Language Processing (NLP - Doğal Dil İşleme) 2017'de yayınlanan Transformer makalesiyle tamamen değişime uğradı. Bu alanda artık çok büyük miktarda veriyi (metin) daha hızlı bir şekilde işlemek mümkün oldu.\n",
        "\n",
        "Klasik NLP'de her farklı görev için yeni bir model eğitilirken günümüzde çok büyük miktarlarda veriler toplanıp devasa modeller eğitiliyor. Daha sonra bu modeller çeşitli amaçlar için fine-tune (son halini verme) işleminden geçirilip kullanıma sunuluyor.\n",
        "\n",
        "Bugün çeşitli yapay zeka görevleri için örnekler deneyeceğiz. Bunlar NLP alanından olacak, çünkü görüntü işlemek daha çok zaman ve işlem gücü gerektiriyor.\n",
        "\n",
        "**HuggingFace🤗:** [Hugging Face](https://huggingface.co), transformer temelli yapay zeka modellerini ve verisetlerini bir araya getiren bir şirket ve açık kaynak topluluğu. Araştırmacılar ve yapay zeka şirketleri akademik veya iş amaçlı geliştirdikleri model ve verisetlerini Hugging Face üzerinde yayınlıyorlar. Kolaylık adına biz de bugün [Hugging Face modelleri](https://huggingface.co/facebook/bart-large-cnn) üzerinde denemeler yapacağız."
      ],
      "metadata": {
        "id": "xdHsu_bltV2t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Summarization (Metin Özetleme)\n",
        "\n",
        "Facebook tarafından yayınlanan BART (*BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension, [makale](https://arxiv.org/abs/1910.13461)*) modeliyle metin özetleme denemeleri yapalım."
      ],
      "metadata": {
        "id": "Ay3ZWHtgjmbD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BartForConditionalGeneration, BartTokenizer\n",
        "\n",
        "# Ön eğitimden geçirilmiş modeli indirelim.\n",
        "model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large-cnn\")\n",
        "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
        "\n",
        "def generate_summary(text):\n",
        "    '''BART modelini kullanarak özet üreten model fonksiyonu.'''\n",
        "\n",
        "    # Metinleri matematiksel hale çevirelim.\n",
        "    inputs = tokenizer([text], max_length=1024, return_tensors='pt', truncation=True)\n",
        "\n",
        "    # Modeli kullanarak özeti üretelim.\n",
        "    summary_ids = model.generate(inputs['input_ids'], num_beams=4, min_length=30, max_length=200, early_stopping=True)\n",
        "\n",
        "    # Model bize matematiksel bir çıktı veriyor.\n",
        "    # Bu çıktıyı tekrar metin haline çevirelim.\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
        "    return summary"
      ],
      "metadata": {
        "id": "HzvFreynWZQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yukarıdaki hücreyi her çalıştırdığımızda modeli internetten indireceği için bunu önleyip denemelerimizi aşağıdaki hücrede gerçekleştirelim."
      ],
      "metadata": {
        "id": "RiDKOBnwo-5i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example text to summarize\n",
        "input_text = \"\"\"\n",
        "Your input text goes here. This can be a long document or an article that you want to summarize.\n",
        "\"\"\"\n",
        "\n",
        "# Generate the summary\n",
        "summary = generate_summary(input_text)\n",
        "print(\"Generated Summary:\")\n",
        "print(summary)"
      ],
      "metadata": {
        "id": "rngb706kW6dr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Translation (Metin Çevirisi)\n",
        "\n",
        "Google'ın yayınlamış olduğu T5 modeli (*T5: Text-To-Text Transfer Transformer, [makale](https://arxiv.org/abs/1910.10683), [kod](https://github.com/google-research/text-to-text-transfer-transformer)*) ile metin çevirisi deneyelim.\n",
        "\n",
        "Zaman tasarrufu adına `t5-small` veya `t5-base` modelini kullanıyoruz. Daha başarılı sonuçlar için `t5-large`, `t5-3b` veya `t5-5b` de kullanılabilir. Aşağıdaki kodda `t5-small` ifadelerini değiştirerek deneyebilirsiniz."
      ],
      "metadata": {
        "id": "aT-TdhRgkUZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
        "\n",
        "# Ön eğitimden geçirilmiş modeli indirelim.\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
        "\n",
        "def translate_text(input_text, target_language=\"fr\"):\n",
        "    '''T5 modelini kullanarak çeviri yapan model fonksiyonu.'''\n",
        "\n",
        "    # Metinleri matematiksel hale çevirelim.\n",
        "    input_text = \"translate English to \" + target_language + \": \" + input_text\n",
        "    inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "\n",
        "    # Modeli çalıştıralım.\n",
        "    translation_ids = model.generate(inputs.input_ids, max_length=512, num_beams=4, early_stopping=True)\n",
        "\n",
        "    # Model bize matematiksel bir çıktı veriyor.\n",
        "    # Bu çıktıyı tekrar metin haline çevirelim.\n",
        "    translation = tokenizer.decode(translation_ids[0], skip_special_tokens=True)\n",
        "    return translation"
      ],
      "metadata": {
        "id": "EhzhO4M7XhXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Çevirileri test edelim:"
      ],
      "metadata": {
        "id": "Ynm3Ei8YkfFT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example text for translation\n",
        "input_text = \"Hello, how are you?\"\n",
        "\n",
        "# Translate the text to French\n",
        "translated_text = translate_text(input_text, target_language=\"fr\")\n",
        "print(\"Translated Text:\")\n",
        "print(translated_text)"
      ],
      "metadata": {
        "id": "Lnwi7MMTkejN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Generation (Metin Üretimi)\n",
        "\n",
        "Son olarak transformer'lar ile metin üretimini deneyelim."
      ],
      "metadata": {
        "id": "_DAxvOK4kg05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model directly\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# Ön eğitimden geçirilmiş modeli indirelim.\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilgpt2\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"distilbert/distilgpt2\")\n",
        "\n",
        "def generate_text(prompt, max_length=100):\n",
        "    # Metinleri matematiksel hale çevirelim.\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "\n",
        "    # Modeli çalıştıralım.\n",
        "    output = model.generate(input_ids, max_length=max_length, num_return_sequences=1,\n",
        "                            no_repeat_ngram_size=2, top_k=50, top_p=0.95, temperature=0.7,\n",
        "                            do_sample=True)\n",
        "\n",
        "    # Çıktıyı tekrar metin haline çevirelim.\n",
        "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    return generated_text"
      ],
      "metadata": {
        "id": "e6DsJOyvkla8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modeli test edelim:"
      ],
      "metadata": {
        "id": "acEnVipWkx1P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Example prompt for text generation\n",
        "prompt = \"Once upon a time, in a land far away, there lived a\"\n",
        "\n",
        "# Generate text based on the prompt\n",
        "generated_text = generate_text(prompt, max_length=150)\n",
        "print(\"Generated Text:\")\n",
        "print(generated_text)"
      ],
      "metadata": {
        "id": "s0sbOAf0krVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Son Notlar"
      ],
      "metadata": {
        "id": "-8bICxFPkzs0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bu atölyede yapay zekanın yapabileceklerinin bir kısmını gördük ve temellerini biraz inceledik. Son 15 yılda ciddi gelişmeeler yaşanmış olan yapay zekanın kapasiteleri bundan çok daha derin ve bu alan akademide oldukça geniş."
      ],
      "metadata": {
        "id": "q1sUfTRxs_7k"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "nav_menu": {},
    "toc": {
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 6,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}